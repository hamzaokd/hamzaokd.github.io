---
layout: md
---

<div class="row">
<div class="sidebar">
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#fraud-detection-in-credit-card-transactions">Fraud detection in credit card transactions</a>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#data">Data</a>
<ul>
<li><a href="#features">Features</a></li>
<li><a href="#missing-values">Missing values</a></li>
<li><a href="#statistics">Statistics</a></li>
</ul></li>
<li><a href="#analysis">Analysis</a>
<ul>
<li><a href="#complete-data">1. Complete data:</a></li>
<li><a href="#upsampling-with-duplicates">2. UpSampling with duplicates:</a></li>
<li><a href="#upsampling-with-smote-method">3. UpSampling with SMOTE method:</a></li>
<li><a href="#weighted-logistic-regression">4. Weighted logistic regression:</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
</div>
<div class="main">
<h1 id="fraud-detection-in-credit-card-transactions">Fraud detection in credit card transactions</h1>
<h2 id="introduction">Introduction</h2>
<p>The objective of this project is the unbalanced classification of data. This class imbalance clearly increases the difficulty of learning by the classification algorithm. This is because the algorithm has only a few examples of the minority class to learn from. It is therefore biased towards the population of negatives and produces predictions that are potentially less robust than in the absence of imbalance.</p>
<h2 id="data">Data</h2>
<p>We will use the credit card fraud dataset from <a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud">Kaggle</a>. The dataset contains a set of transactions from a credit card company.</p>
<h3 id="features">Features</h3>
<p>It presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.</p>
<p>There are 31 variables in this database, 28 of which come from a PCA transformation (principal component analysis) because unfortunately the primary characteristics contain confidential data that cannot be provided. These variables are columns <code>V1</code>, <code>V2</code>, …, up to <code>V28</code>.</p>
<p>The only data that has not been transformed are the <code>Time</code>, <code>Amount</code> and <code>Class</code> columns.</p>
<ul>
<li><p><code>Time</code> contains the elapsed time between each transaction and the first database transaction.</p></li>
<li><p><code>Amount</code> on the other hand contains transaction amounts and this feature can be useful in recognizing the sensitivity and importance of transaction costs.</p></li>
<li><p>Finally, <code>Class</code> is the last variable which is worth 1 if the transaction is a fraud and 0 otherwise.</p></li>
</ul>
<h3 id="missing-values">Missing values</h3>
<p>There are no missing values in this dataset.</p>
<h3 id="statistics">Statistics</h3>
<ul>
<li><strong>Transaction amount distribution:</strong></li>
</ul>
<figure>
<img src="amount%20distr.png" alt="amount distribution" /><figcaption aria-hidden="true">amount distribution</figcaption>
</figure>
<p>For transaction amounts, we notice that the median of fraudulent transactions is lower. This is due to the fact that during an operation, it is better to carry out several transactions of small amounts in order not to be distinguished.</p>
<ul>
<li><strong>Time distribution:</strong></li>
</ul>
<figure>
<img src="time%20distr.png" alt="time distribution" /><figcaption aria-hidden="true">time distribution</figcaption>
</figure>
<ul>
<li><strong>Correlation matrix:</strong></li>
</ul>
<p>As mentioned before, the database is the result of a principal component analysis, so a priori there is no need to check for relevancy between the columns. And as a result, the correlation matrix is very sparse.</p>
<figure>
<img src="cprr%20matrix.png" alt="correlation matrix" /><figcaption aria-hidden="true">correlation matrix</figcaption>
</figure>
<p>We note that there is a correlation between the <code>Amount</code> and <code>Class</code> variables which may allow us to facilitate the classification later, to guess if a transaction is fraudulent or not, since the amount of a transaction can be an important factor in deciding whether a transaction is fraudulent or not.</p>
<h2 id="analysis">Analysis</h2>
<p>In our analysis, we will use a logistic regression classifier to classify the transactions.</p>
<p>The logistic regression algorithm will measure the relationship between the “Label” Y and the “Features” X by estimating the probabilities using a logistic function called a sigmoid function. This is the function represented in the following figure and which aims to separate fraudulent transactions from non-fraudulent ones.</p>
<figure>
<img src="logregr.png" alt="Logistic function" /><figcaption aria-hidden="true">Logistic function</figcaption>
</figure>
<p><em>In all the following models, we will separate our data set into 2 groups: a training set and a test set. The regression is performed with a decision threshold of 0.5.</em></p>
<p>We will first use the classification on all our data.</p>
<h3 id="complete-data">1. Complete data:</h3>
<p>-&gt; Occurences of classes in the training set:</p>
<pre><code>    0         1
    181953   323</code></pre>
<p>We apply the logistic regression algorithm to the complete data set.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>   model <span class="ot">&lt;-</span> <span class="fu">glm</span>(Fraud<span class="sc">~</span>., <span class="at">data =</span> train_set, <span class="at">family =</span> binomial )</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, test_set, <span class="at">type=</span><span class="st">&#39;response&#39;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    predictions.results <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(predictions <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">&quot;1&quot;</span>, <span class="st">&quot;0&quot;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">confusionMatrix</span>(<span class="fu">as.factor</span>(predictions.results), <span class="fu">as.factor</span>(test_set<span class="sc">$</span>Fraud), <span class="at">positive =</span> <span class="st">&quot;1&quot;</span>)</span></code></pre></div>
<pre><code>    Confusion Matrix and Statistics

          Reference
    Prediction     0     1
            0 45483    33
            1     6    47
                                          
               Accuracy : 0.9991          
                 95% CI : (0.9988, 0.9994)
    No Information Rate : 0.9982          
    P-Value [Acc &gt; NIR] : 2.756e-07       
                                          
                  Kappa : 0.7064          
                                          
    Mcnemar&#39;s Test P-Value : 3.136e-05       
                                          
            Sensitivity : 0.587500        
            Specificity : 0.999868        
         Pos Pred Value : 0.886792        
         Neg Pred Value : 0.999275        
             Prevalence : 0.001756        
         Detection Rate : 0.001031        
    Detection Prevalence : 0.001163        
      Balanced Accuracy : 0.793684        
                                          
       &#39;Positive&#39; Class : 1                        </code></pre>
<p>We note that the accuracy of our model is 99.9%. At first glance, the model seems efficient, but in the case of class imbalance, the accuracy can be misleading. With a dataset of two classes, where the first class represents 99% of the data, if the classifier predicts that each example belongs to the first class, the accuracy will be 99%, but this classifier is useless in practice.</p>
<h3 id="upsampling-with-duplicates">2. UpSampling with duplicates:</h3>
<p>Upsampling or random oversampling consists of supplementing the training data with multiple copies of some instances of the minority class.</p>
<pre><code>-&gt; Occurences of classes in the training set:

    0      1 
    284315 284315 </code></pre>
<p>We can see that our data has become balanced after adding several copies of fraudulent transactions.</p>
<p>We then perform the logistic regression:</p>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 44547  3594
         1   943 41896
                                          
               Accuracy : 0.9501          
                 95% CI : (0.9487, 0.9515)
    No Information Rate : 0.5             
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.9003          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9210          
            Specificity : 0.9793          
         Pos Pred Value : 0.9780          
         Neg Pred Value : 0.9253          
             Prevalence : 0.5000          
         Detection Rate : 0.4605          
   Detection Prevalence : 0.4709          
      Balanced Accuracy : 0.9501          
                                          
       &#39;Positive&#39; Class : 1               
                                          </code></pre>
<p>We obtain a <em>balanced accuracy</em> of 95%, but with this method we risk having an overfitting for fraudulent transactions.</p>
<h3 id="upsampling-with-smote-method">3. UpSampling with SMOTE method:</h3>
<p>To overcome the disadvantage imposed by a normal upsamling, the Smote method (Synthetic Minority Oversampling Technique) can be used. The idea of ​​SMOTE is to increase the recall for the minority class by generating synthetic individuals on the segments between elements close to the minority class.</p>
<figure>
<img src="smote.png" alt="smote" /><figcaption aria-hidden="true">smote</figcaption>
</figure>
<p>-&gt; Occurences of classes in the training set:</p>
<pre><code>        0      1 
    283884 284376 </code></pre>
<p>We can see that we have generated as many fraudulent transactions as non-fraudulent ones.</p>
<pre><code>Warning message:
&quot;glm.fit: fitted probabilities numerically 0 or 1 occurred&quot;



Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 44378  3406
         1  1040 42096
                                          
               Accuracy : 0.9511          
                 95% CI : (0.9497, 0.9525)
    No Information Rate : 0.5005          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.9022          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9251          
            Specificity : 0.9771          
         Pos Pred Value : 0.9759          
         Neg Pred Value : 0.9287          
             Prevalence : 0.5005          
         Detection Rate : 0.4630          
   Detection Prevalence : 0.4744          
      Balanced Accuracy : 0.9511          
                                          
       &#39;Positive&#39; Class : 1               
                                          </code></pre>
<p>The regression model became more efficient with a balanced accuracy of 95.11%.</p>
<p>But this model can lead to errors in our model, especially since in the banking sector, we work with sensitive data to detect fraud. So we cannot generate data (~240000 fraudulent transactions) to model the logistic regression.</p>
<h3 id="weighted-logistic-regression">4. Weighted logistic regression:</h3>
<p>In most machine learning models, they accept a <code>weight</code> parameter. It is used to apply a cost inversely proportional to the class imbalance. Visually, this allows to bias the model towards the minority class as illustrated below where the decision boundary of a linear kernel SVM is translated towards the minority class. <img src="w.png" alt="weighted" />.</p>
<p>In our case, we define the weight of the minority class as follow:</p>
<p><span class="math display">\[
\text{weight}= \frac{\sum(\text{non frauduleuses)}}{\sum(\text{frauduleuses)}}
\]</span></p>
<p>We apply the weighted logistic regression:</p>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 45490     0
         1     0    78
                                     
               Accuracy : 1          
                 95% CI : (0.9999, 1)
    No Information Rate : 0.9983     
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
                                     
                  Kappa : 1          
                                     
 Mcnemar&#39;s Test P-Value : NA         
                                     
            Sensitivity : 1.000000   
            Specificity : 1.000000   
         Pos Pred Value : 1.000000   
         Neg Pred Value : 1.000000   
             Prevalence : 0.001712   
         Detection Rate : 0.001712   
   Detection Prevalence : 0.001712   
      Balanced Accuracy : 1.000000   
                                     
       &#39;Positive&#39; Class : 1 </code></pre>
<p>After training, we see that we have obtained 100% accuracy, the weighted logistic regression method is effective and more suited to our problem!</p>
</div>
</div>

