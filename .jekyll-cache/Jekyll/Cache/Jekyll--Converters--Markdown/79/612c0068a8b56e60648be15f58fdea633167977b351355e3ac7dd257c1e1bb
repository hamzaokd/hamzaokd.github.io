I"ê<h1 id="tumor-detection-in-medical-imaging-using-neural-networks"><a href="https://github.com/hamzaokd/LiTS">Tumor detection in medical imaging using neural networks</a></h1>

<h2 id="introduction">Introduction</h2>

<p>In the field of medical imaging, the preprocessing of radiographic images is essential in order to effectively detect cancerous tumours. It also involves locating these tumors and estimating their sizes. In this way, doctors can use this information to diagnose the disease but also monitor the progress of treatment.</p>

<p>In this project, we will seek to detect cancerous tumors in the liver. We will use open access data that have been annotated by experts (radiologists and oncologists): the tumors are therefore known and localized. The figure below gives an idea of â€‹â€‹the images that will be used.</p>

<p><img src="https://github.com/hamzaokd/LiTS/blob/main/media/intro.png" alt="Original-Mask" /></p>

<h2 id="database">Database</h2>

<p>The database contains 131 original X-ray images and their corresponding mask images, or 232 images in total, in NII format.
The database can be found in the following links <a href="https://www.kaggle.com/andrewmvd/liver-tumor-segmentation">part1</a> and <a href="https://www.kaggle.com/andrewmvd/liver-tumor-segmentation-part-2">part2</a>.</p>
<h2 id="study-of-tumors">Study of tumors</h2>
<p>We will gather the 232 images in a dataframe containing for each of the 131 original images its source file, its name, the source file of its â€œmaskâ€ image and the name of the latter.</p>

<p>After studying the nii images, we managed to understand our data. Indeed, these are 3D images of dimensions 512 x 512 x n, with n changing from one image to another.</p>

<p>We add two columns to the dataframe: one that shows whether the image contains a tumor or not and the other displays its percentage.
<img src="https://github.com/hamzaokd/LiTS/blob/main/media/database.PNG" alt="dataframe" /></p>

<h2 id="image-conversion">Image conversion</h2>

<p>We chose to use the U-Net neural network, a network designed and applied for the first time in 2015 by Oral Ronneberger for the segmentation of medical images.</p>

<p>In addition to having the correct format for U-Net, having jpg or png images will be very useful since our database is very large (49.9 GB), so the manipulation of x-ray images in the NII format takes a lot of time and memory. With this in mind, we are going to transform the 3D images from NII format into 2D images of regular formats: <strong>a 3D image of dimensions 512x512x n will be transformed into n images 512x512.</strong></p>

<p>The original images will be transformed into images in jpg format after having preprocessed them thanks to the functions of the fastai library. As for the â€œmaskâ€ images, we will use the png format. This choice is due to the fact that the â€œlabelsâ€ 1,2 and 3 contained in an NII â€œmaskâ€ image are lost if this image is transformed into a jpg image, unlike the png format which retains the â€œlabelsâ€ well.</p>

<p>After preprocessing we obtain images of the form:
<img src="https://github.com/hamzaokd/LiTS/blob/main/media/output.png" alt="output" /></p>

<h2 id="implementing-u-net">Implementing U-Net</h2>

<p>The implementation, training and prediction part is detailed in the report of another team</p>

<ul>
  <li>After training the images, we obtain the following predicted images</li>
</ul>

<h2 id="report">Report</h2>
<p>Our report can be found in <a href="https://github.com/hamzaokd/LiTS/blob/main/Rapport_LOUTAOUI_OUKADDI.pdf">here</a>
***</p>

<p><br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<strong>French version</strong></p>

<h1 id="dÃ©tection-de-tumeurs-avec-un-rÃ©seau-de-neurones-en-imagerie-mÃ©dicale"><a href="https://github.com/hamzaokd/LiTS">DÃ©tection de tumeurs avec un rÃ©seau de neurones en imagerie mÃ©dicale</a></h1>
<hr />

<h2 id="introduction-1">Introduction</h2>

<p>Dans le domaine de lâ€™imagerie mÃ©dicale, le prÃ©traitement des images radiographiques est essentiel afin de dÃ©tecter efficacement des tumeurs cancÃ©reuses. Il sâ€™agit Ã©galement de localiser ces tumeurs et dâ€™estimer leurs tailles. De cette maniÃ¨re, les mÃ©decins peuvent exploiter ces informations pour diagnostiquer la maladie mais aussi suivre lâ€™Ã©volution du traitement.</p>

<p>Dans ce projet, nous chercheronls Ã  dÃ©tecter des tumeurs cancÃ©reuses dans le foie. Nous utiliserons des donnÃ©es en accÃ¨s libre qui ont Ã©tÃ© annontÃ©es par des experts (radiologistes et oncologues): les tumeurs sont donc connues et localisÃ©es. La figure ci-aprÃ¨s donne une idÃ©e des images qui seront utilisÃ©es.</p>

<p><img src="https://github.com/hamzaokd/LiTS/blob/main/media/intro.png" alt="Original-Mask" /></p>

<h2 id="base-de-donnÃ©es">Base de donnÃ©es</h2>

<p>La base de donnÃ©e contient 131 images radiographiques originales et leur images â€œmasksâ€ correspondants, soit 232 images au total, en format NII. 
La base donnÃ©es se trouve dans les liens suivants <a href="https://www.kaggle.com/andrewmvd/liver-tumor-segmentation">part1</a> et <a href="https://www.kaggle.com/andrewmvd/liver-tumor-segmentation-part-2">part2</a></p>

<h2 id="Ã©tude-des-tumeurs">Ã‰tude des tumeurs</h2>
<p>On va rassembler les 232 images dans un dataframe contenant pour chacune des 131 images originales son fichier source, son nom, le fichier source de son image â€œmaskâ€ et le nom de cette derniÃ¨re.</p>

<p>Apres lâ€™etude des images nii, On a reussit a comprendre nos donnes. En effet, il sâ€™agit des images 3D de dimensions 512 x 512 x n, avec n qui chnage dâ€™une image a lâ€™autre.</p>

<p>On ajoute au dataframe deux colones: une qui montre si lâ€™image contient une tumeur ou pas et lâ€™autre affiche son pourcentage.
<img src="https://github.com/hamzaokd/LiTS/blob/main/media/database.PNG" alt="dataframe" /></p>

<h3 id="conversion-des-images-nii">Conversion des images NII</h3>

<p>Nous avons choisi dâ€™utiliser le rÃ©seau de neuronnes U-Net, un rÃ©seau conÃ§u et appliquÃ© pour la premiÃ¨re fois en 2015 par Oral Ronneberger pour la segmentation dâ€™images mÃ©dicales.</p>

<p>En plus dâ€™avoir le bon format pour U-Net, avoir des images jpg ou png va Ãªtre trÃ¨s utile vu que notre base de donnÃ©es est trÃ¨s volumineuse (49,9 Go), donc la manipulation  des images radiographiques sous le format NII prend beaucoup de temps et de mÃ©moire. Dans cette optique, nous allons transformer les images 3D en format NII en images 2D de formats rÃ©guliers: <strong>une image 3D de dimensions 512x512x n va Ãªtre transformÃ©e en n images 512x512.</strong></p>

<p>Les images originaux seront transformÃ©es Ã  des images en format jpg aprÃ¨s les avoir prÃ©traitÃ© grÃ¢ce aux fonctions de la librairie fastai. Tant que pour les images â€œmaskâ€, nous allons utiliser le format png. Ce choix est dÃ» au fait que les â€œlabelsâ€ 1,2 et 3 que contient une image â€œmaskâ€ NII sont perdus si on transforme cette image en une image jpg, contrairement au format png qui conserve bien les â€œlabelsâ€.</p>

<p>Apres un pretraitement on obtient des images de la forme:
<img src="https://github.com/hamzaokd/LiTS/blob/main/media/output.png" alt="output" /></p>

<h2 id="implÃ©mentation-de-u-net">ImplÃ©mentation de U-Net</h2>

<p>La partie dâ€™implÃ©mentation, dâ€™entraÃ®nement et de prÃ©diction est dÃ©taillÃ©e dans le rapport dâ€™une autre equipe</p>

<ul>
  <li>Apres lâ€™entraÃ®nement des images, on obtient les images prÃ©dites suivantes</li>
</ul>

<h2 id="rapport">Rapport</h2>

<p>Notre <a href="https://github.com/hamzaokd/LiTS/blob/main/Rapport_LOUTAOUI_OUKADDI.pdf">rapport</a></p>
:ET